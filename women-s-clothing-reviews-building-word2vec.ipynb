{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "949268b8",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-03-01T12:14:21.548613Z",
     "iopub.status.busy": "2023-03-01T12:14:21.548091Z",
     "iopub.status.idle": "2023-03-01T12:14:21.572899Z",
     "shell.execute_reply": "2023-03-01T12:14:21.571468Z"
    },
    "papermill": {
     "duration": 0.037182,
     "end_time": "2023-03-01T12:14:21.575475",
     "exception": false,
     "start_time": "2023-03-01T12:14:21.538293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/reviews-cleaned/reviews_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97369813",
   "metadata": {
    "papermill": {
     "duration": 0.005497,
     "end_time": "2023-03-01T12:14:21.587442",
     "exception": false,
     "start_time": "2023-03-01T12:14:21.581945",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Women's Clothing Reviews - Sentiment Analysis: Building Word2Vec\n",
    "\n",
    "## Overall Project Goal\n",
    "In this project I want to understand this dataset on women's clothing reviews, create a Word2Vec model based off of the review texts in the data set and then use this Word2Vec model to build a sentiment analysis model on the dataset which attempts to predict whether the customer left a 5-star review or not.\n",
    "\n",
    "### Project Notebooks\n",
    "This notebook is part of a series of 3 notebooks on performing sentiment analysis on a dataset of women's clothing reviews.\n",
    "1. Women's Clothing Reviews - Sentiment Analysis: EDA **{ADD LINKS}**\n",
    "2. **Women's Clothing Reviews - Sentiment Analysis: Building Word2Vec Model** \n",
    "3. Women's Clothing Reviews - Sentiment Analysis: Building a Sentiment Analysis Model\n",
    "\n",
    "\n",
    "\n",
    "## Goal of this notebook: Building Word2Vec Model\n",
    "In this notebook, I want to take all the text in the dataset, preprocess it and use it to build a Word2Vec model that can then be used to vectorise the data and use it in a neural network for the task of sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea211464",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-01T12:14:21.600580Z",
     "iopub.status.busy": "2023-03-01T12:14:21.600152Z",
     "iopub.status.idle": "2023-03-01T12:14:24.012339Z",
     "shell.execute_reply": "2023-03-01T12:14:24.011286Z"
    },
    "papermill": {
     "duration": 2.422317,
     "end_time": "2023-03-01T12:14:24.015423",
     "exception": false,
     "start_time": "2023-03-01T12:14:21.593106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Linear algebra and data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data vizualisation\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# Data preprocessing\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Importing the model\n",
    "from gensim.models import word2vec, Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cea251f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-01T12:14:24.031272Z",
     "iopub.status.busy": "2023-03-01T12:14:24.030270Z",
     "iopub.status.idle": "2023-03-01T12:14:24.297781Z",
     "shell.execute_reply": "2023-03-01T12:14:24.296876Z"
    },
    "papermill": {
     "duration": 0.277956,
     "end_time": "2023-03-01T12:14:24.300375",
     "exception": false,
     "start_time": "2023-03-01T12:14:24.022419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/kaggle/input/reviews-cleaned/reviews_cleaned.csv', index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b7ef854",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-01T12:14:24.314279Z",
     "iopub.status.busy": "2023-03-01T12:14:24.313617Z",
     "iopub.status.idle": "2023-03-01T12:14:24.332890Z",
     "shell.execute_reply": "2023-03-01T12:14:24.332090Z"
    },
    "papermill": {
     "duration": 0.028573,
     "end_time": "2023-03-01T12:14:24.334990",
     "exception": false,
     "start_time": "2023-03-01T12:14:24.306417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Five Star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22636</th>\n",
       "      <td>Great dress for many occasions</td>\n",
       "      <td>I was very happy to snag this dress at such a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22637</th>\n",
       "      <td>Wish it was made of cotton</td>\n",
       "      <td>It reminds me of maternity clothes. soft, stre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22638</th>\n",
       "      <td>Cute, but see through</td>\n",
       "      <td>This fit well, but the top was very see throug...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22639</th>\n",
       "      <td>Very cute dress, perfect for summer parties an...</td>\n",
       "      <td>I bought this dress for a wedding i have this ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22640</th>\n",
       "      <td>Please make more like this one!</td>\n",
       "      <td>This dress in a lovely platinum is feminine an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22641 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Title  \\\n",
       "0                                                    NaN   \n",
       "1                                                    NaN   \n",
       "2                                Some major design flaws   \n",
       "3                                       My favorite buy!   \n",
       "4                                       Flattering shirt   \n",
       "...                                                  ...   \n",
       "22636                     Great dress for many occasions   \n",
       "22637                         Wish it was made of cotton   \n",
       "22638                              Cute, but see through   \n",
       "22639  Very cute dress, perfect for summer parties an...   \n",
       "22640                    Please make more like this one!   \n",
       "\n",
       "                                             Review Text  Five Star  \n",
       "0      Absolutely wonderful - silky and sexy and comf...          0  \n",
       "1      Love this dress!  it's sooo pretty.  i happene...          1  \n",
       "2      I had such high hopes for this dress and reall...          0  \n",
       "3      I love, love, love this jumpsuit. it's fun, fl...          1  \n",
       "4      This shirt is very flattering to all due to th...          1  \n",
       "...                                                  ...        ...  \n",
       "22636  I was very happy to snag this dress at such a ...          1  \n",
       "22637  It reminds me of maternity clothes. soft, stre...          0  \n",
       "22638  This fit well, but the top was very see throug...          0  \n",
       "22639  I bought this dress for a wedding i have this ...          0  \n",
       "22640  This dress in a lovely platinum is feminine an...          1  \n",
       "\n",
       "[22641 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355b3b3c",
   "metadata": {
    "papermill": {
     "duration": 0.005822,
     "end_time": "2023-03-01T12:14:24.347165",
     "exception": false,
     "start_time": "2023-03-01T12:14:24.341343",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87dc9cc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-01T12:14:24.361403Z",
     "iopub.status.busy": "2023-03-01T12:14:24.360747Z",
     "iopub.status.idle": "2023-03-01T12:14:24.366000Z",
     "shell.execute_reply": "2023-03-01T12:14:24.365236Z"
    },
    "papermill": {
     "duration": 0.014938,
     "end_time": "2023-03-01T12:14:24.368086",
     "exception": false,
     "start_time": "2023-03-01T12:14:24.353148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# importing a lemmatizer\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def lemmatize(words):\n",
    "    # This function takes in a list of words and returns the list\n",
    "    # of words with the words in their lemmatized form\n",
    "    # it priotizes correctly lemmatizing verbs\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word, pos='v') for word in words]\n",
    "    return lemmatized_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3b7952f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-01T12:14:24.382519Z",
     "iopub.status.busy": "2023-03-01T12:14:24.381850Z",
     "iopub.status.idle": "2023-03-01T12:14:24.387922Z",
     "shell.execute_reply": "2023-03-01T12:14:24.386707Z"
    },
    "papermill": {
     "duration": 0.016419,
     "end_time": "2023-03-01T12:14:24.390706",
     "exception": false,
     "start_time": "2023-03-01T12:14:24.374287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def review_to_wordlist(review):\n",
    "    \n",
    "    # This is our data preprocessing function that removes HTML, removes non letters and \n",
    "    # returns the review with words split into items in a list and all in lowercase.\n",
    "    \n",
    "    # Remove HTML\n",
    "    review = BeautifulSoup(review).get_text()\n",
    "    \n",
    "    # Remove non-letters\n",
    "    review = re.sub(\"[^a-zA-Z]\", \" \", review)\n",
    "    \n",
    "    # Convert words to lowercase and split them\n",
    "    review = review.lower().split()\n",
    "    \n",
    "    # Lemmatize the words\n",
    "    review = lemmatize(review)\n",
    "    \n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98efec22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-01T12:14:24.405367Z",
     "iopub.status.busy": "2023-03-01T12:14:24.404966Z",
     "iopub.status.idle": "2023-03-01T12:14:26.412389Z",
     "shell.execute_reply": "2023-03-01T12:14:26.411298Z"
    },
    "papermill": {
     "duration": 2.017821,
     "end_time": "2023-03-01T12:14:26.415137",
     "exception": false,
     "start_time": "2023-03-01T12:14:24.397316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['love', 'this', 'dress', 'it', 's', 'sooo', 'pretty', 'i', 'happen', 'to']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of results of review_to_wordlist\n",
    "review_to_wordlist(data['Review Text'][1])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51daff15",
   "metadata": {
    "papermill": {
     "duration": 0.00595,
     "end_time": "2023-03-01T12:14:26.427498",
     "exception": false,
     "start_time": "2023-03-01T12:14:26.421548",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Word2Vec expects to recieve text in a specific format. It expects single sentences as a list of words. The input format is therefore a list of lists breaking down the text into sentences and words. We will use the tokenizer to define the different sentences in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7e0d27f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-01T12:14:26.442437Z",
     "iopub.status.busy": "2023-03-01T12:14:26.441774Z",
     "iopub.status.idle": "2023-03-01T12:14:26.458581Z",
     "shell.execute_reply": "2023-03-01T12:14:26.457552Z"
    },
    "papermill": {
     "duration": 0.027634,
     "end_time": "2023-03-01T12:14:26.461464",
     "exception": false,
     "start_time": "2023-03-01T12:14:26.433830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download the punkt tokenizer for sentence splitting\n",
    "import nltk.data\n",
    "\n",
    "# Load the punkt tokenizer\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "315aa404",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-01T12:14:26.475913Z",
     "iopub.status.busy": "2023-03-01T12:14:26.475493Z",
     "iopub.status.idle": "2023-03-01T12:14:26.482882Z",
     "shell.execute_reply": "2023-03-01T12:14:26.481661Z"
    },
    "papermill": {
     "duration": 0.017257,
     "end_time": "2023-03-01T12:14:26.485216",
     "exception": false,
     "start_time": "2023-03-01T12:14:26.467959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def review_to_sentences(review, tokenizer):\n",
    "    # This function splits the review into passed sentences\n",
    "    # and returns a list of sentences, where each sentence is a list of words\n",
    "    \n",
    "    # Using the tokeniser to split the reivew into sentences\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "    \n",
    "    \n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentence) > 0:\n",
    "            # Using the review_to_wordlist function to return a list of lists\n",
    "            sentences.append(review_to_wordlist(raw_sentence))\n",
    "\n",
    "    return sentences\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92f4303d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-01T12:14:26.499521Z",
     "iopub.status.busy": "2023-03-01T12:14:26.499137Z",
     "iopub.status.idle": "2023-03-01T12:14:26.540204Z",
     "shell.execute_reply": "2023-03-01T12:14:26.538984Z"
    },
    "papermill": {
     "duration": 0.050968,
     "end_time": "2023-03-01T12:14:26.542496",
     "exception": false,
     "start_time": "2023-03-01T12:14:26.491528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace missing values with a space character\n",
    "data['Title'] = data['Title'].apply(lambda x: ' ' if pd.isna(x) else x)\n",
    "\n",
    "# Creating a new column that contains the title and review text together\n",
    "data['Total Text'] = data['Title'] + '. ' +data['Review Text'] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18fc08df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-01T12:14:26.558436Z",
     "iopub.status.busy": "2023-03-01T12:14:26.557589Z",
     "iopub.status.idle": "2023-03-01T12:15:13.908974Z",
     "shell.execute_reply": "2023-03-01T12:15:13.907883Z"
    },
    "papermill": {
     "duration": 47.362142,
     "end_time": "2023-03-01T12:15:13.911619",
     "exception": false,
     "start_time": "2023-03-01T12:14:26.549477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 reviews processed in data out of 22641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/bs4/__init__.py:439: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 reviews processed in data out of 22641\n",
      "10000 reviews processed in data out of 22641\n",
      "15000 reviews processed in data out of 22641\n",
      "20000 reviews processed in data out of 22641\n"
     ]
    }
   ],
   "source": [
    "# Defining the empty list to put the sentences in\n",
    "sentences = []\n",
    "\n",
    "# Preprocessing the reviews in `train_labeled` and appending to list\n",
    "for i, review in enumerate(data['Total Text']):\n",
    "    if i%5000 == 0:\n",
    "        print(f'{i} reviews processed in data out of {len(data)}')\n",
    "    sentences += review_to_sentences(review, tokenizer)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c63838fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-01T12:15:13.927522Z",
     "iopub.status.busy": "2023-03-01T12:15:13.926562Z",
     "iopub.status.idle": "2023-03-01T12:15:13.963609Z",
     "shell.execute_reply": "2023-03-01T12:15:13.962405Z"
    },
    "papermill": {
     "duration": 0.047823,
     "end_time": "2023-03-01T12:15:13.966342",
     "exception": false,
     "start_time": "2023-03-01T12:15:13.918519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 131,187 sentences and a total of 1,441,977 words\n"
     ]
    }
   ],
   "source": [
    "# Seeing how many sentences and words are in the corpus\n",
    "num_sent = len(sentences)\n",
    "num_words = sum(len(sentence) for sentence in sentences)\n",
    "\n",
    "print(f'The dataset contains {num_sent:,} sentences and a total of {num_words:,} words')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b6320d",
   "metadata": {
    "papermill": {
     "duration": 0.006383,
     "end_time": "2023-03-01T12:15:13.979467",
     "exception": false,
     "start_time": "2023-03-01T12:15:13.973084",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "108,438 // 1,375,783 (numbers of sentences and words of review only)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969bd967",
   "metadata": {
    "papermill": {
     "duration": 0.006559,
     "end_time": "2023-03-01T12:15:13.992626",
     "exception": false,
     "start_time": "2023-03-01T12:15:13.986067",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Training the Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3112c518",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-01T12:15:14.007530Z",
     "iopub.status.busy": "2023-03-01T12:15:14.007149Z",
     "iopub.status.idle": "2023-03-01T12:15:16.417111Z",
     "shell.execute_reply": "2023-03-01T12:15:16.416035Z"
    },
    "papermill": {
     "duration": 2.420554,
     "end_time": "2023-03-01T12:15:16.419685",
     "exception": false,
     "start_time": "2023-03-01T12:15:13.999131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Finding bigrams from the corpus\n",
    "bigrams = Phrases(sentences=sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0a0e352",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-01T12:15:16.435497Z",
     "iopub.status.busy": "2023-03-01T12:15:16.434782Z",
     "iopub.status.idle": "2023-03-01T12:15:23.052174Z",
     "shell.execute_reply": "2023-03-01T12:15:23.051002Z"
    },
    "papermill": {
     "duration": 6.628568,
     "end_time": "2023-03-01T12:15:23.054965",
     "exception": false,
     "start_time": "2023-03-01T12:15:16.426397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Finding trigrams from the corpus\n",
    "trigrams = Phrases(sentences=bigrams[sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "156ac824",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-01T12:15:23.069924Z",
     "iopub.status.busy": "2023-03-01T12:15:23.069509Z",
     "iopub.status.idle": "2023-03-01T12:16:20.812451Z",
     "shell.execute_reply": "2023-03-01T12:16:20.811310Z"
    },
    "papermill": {
     "duration": 57.75397,
     "end_time": "2023-03-01T12:16:20.815780",
     "exception": false,
     "start_time": "2023-03-01T12:15:23.061810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# This is so we can see how the training is going\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "print(logging.getLogger().isEnabledFor(logging.INFO))\n",
    "\n",
    "# Defining the model parameters\n",
    "num_features = 300    # Word vector dimensionality                      \n",
    "min_word_count = 30   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 20          # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "\n",
    "# Calling the model\n",
    "model = word2vec.Word2Vec(\n",
    "    sentences=trigrams[bigrams[sentences]], \n",
    "    workers=num_workers,\n",
    "    vector_size=num_features, \n",
    "    min_count=min_word_count,\n",
    "    window=context,\n",
    "    sample=downsampling,\n",
    ")\n",
    "\n",
    "# Makes the model more memory efficient\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "# Saving the model\n",
    "model_name = \"wcr_trigrams_300features_30minwords_20context\" # 'wcr' stands for womens clothes reviews\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50211212",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-01T12:16:20.832958Z",
     "iopub.status.busy": "2023-03-01T12:16:20.832286Z",
     "iopub.status.idle": "2023-03-01T12:16:20.845681Z",
     "shell.execute_reply": "2023-03-01T12:16:20.843790Z"
    },
    "papermill": {
     "duration": 0.027011,
     "end_time": "2023-03-01T12:16:20.850370",
     "exception": false,
     "start_time": "2023-03-01T12:16:20.823359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('large', 0.830851137638092),\n",
       " ('small', 0.775022029876709),\n",
       " ('tight', 0.7276830673217773),\n",
       " ('huge', 0.7088731527328491),\n",
       " ('snug', 0.7063732147216797),\n",
       " ('baggy', 0.6501529216766357),\n",
       " ('tight_across', 0.6367700099945068),\n",
       " ('roomy', 0.6163930296897888),\n",
       " ('loose', 0.5892308354377747),\n",
       " ('larger', 0.5643527507781982)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking some outputs of the model\n",
    "model.wv.most_similar('big')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6e0389",
   "metadata": {
    "papermill": {
     "duration": 0.017749,
     "end_time": "2023-03-01T12:16:20.886996",
     "exception": false,
     "start_time": "2023-03-01T12:16:20.869247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd59d7a9",
   "metadata": {
    "papermill": {
     "duration": 0.017127,
     "end_time": "2023-03-01T12:16:20.921977",
     "exception": false,
     "start_time": "2023-03-01T12:16:20.904850",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# To Do:\n",
    "- Read through and make sure I understand the notebook\n",
    "- Organise the notebook appropiately and add comments and markdown where necessary\n",
    "- Add an extension section\n",
    "    - Should include the pros/ cons of adding another dataset to build the word2vec model\n",
    "- Explore the resulting model a bit further\n",
    "    - Look at most frequent words, least frequent words\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 130.298645,
   "end_time": "2023-03-01T12:16:22.278884",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-01T12:14:11.980239",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
